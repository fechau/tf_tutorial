{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vibloteam/tensorflow_tutorial/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/vibloteam/tensorflow_tutorial/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/vibloteam/tensorflow_tutorial/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/vibloteam/tensorflow_tutorial/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_data = np.random.random((10000, 2))\n",
    "\n",
    "# Fake sample weights\n",
    "sample_weights = np.array([[3, 4]])\n",
    "\n",
    "# Fake y_data\n",
    "y_data = np.matmul(X_data, sample_weights.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = np.add(y_data, np.random.uniform(-0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vibloteam/tensorflow_tutorial/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.0025\n",
    "display_step = 500\n",
    "num_steps = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight and Bias\n",
    "W = tfe.Variable([[1.0, 1.0]])\n",
    "b = tfe.Variable(np.random.uniform(-0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression (Wx + b)\n",
    "def linear_regression(inputs):\n",
    "    return tf.matmul(inputs, W, transpose_b=True) + b\n",
    "\n",
    "# Mean square error\n",
    "def mean_square_fn(model_fn, inputs, labels):\n",
    "    return tf.reduce_mean(tf.square(model_fn(inputs) - labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD Optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "# Compute gradients\n",
    "grad = tfe.implicit_gradients(mean_square_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train cost= 7.283759594 test cost= 7.017067432 W= [[1.0071368 1.0075816]] b= 0.17897414\n",
      "Epoch: 0500 train cost= 0.359400332 test cost= 0.362268418 W= [[1.9841096 2.1830502]] b= 1.6125189\n",
      "Epoch: 1000 train cost= 0.269019544 test cost= 0.274020880 W= [[2.098084  2.4568245]] b= 1.4611386\n",
      "Epoch: 1500 train cost= 0.203500465 test cost= 0.207753628 W= [[2.187382 2.67465 ]] b= 1.2988287\n",
      "Epoch: 2000 train cost= 0.154195309 test cost= 0.157723308 W= [[2.2696612 2.8602393]] b= 1.1562748\n",
      "Epoch: 2500 train cost= 0.117006972 test cost= 0.119900264 W= [[2.3452842 3.0188355]] b= 1.0316079\n",
      "Epoch: 3000 train cost= 0.088901050 test cost= 0.091252476 W= [[2.4144044 3.1545405]] b= 0.9225869\n",
      "Epoch: 3500 train cost= 0.067621648 test cost= 0.069518633 W= [[2.4772787 3.2707975]] b= 0.8272423\n",
      "Epoch: 4000 train cost= 0.051485442 test cost= 0.053006448 W= [[2.5342357 3.3705113]] b= 0.7438535\n",
      "Epoch: 4500 train cost= 0.039232813 test cost= 0.040446028 W= [[2.5856497 3.456129 ]] b= 0.6709175\n",
      "Epoch: 5000 train cost= 0.029917864 test cost= 0.030881314 W= [[2.6319163 3.5297246]] b= 0.6071208\n",
      "Epoch: 5500 train cost= 0.022828994 test cost= 0.023591202 W= [[2.6734369 3.593052 ]] b= 0.5513158\n",
      "Epoch: 6000 train cost= 0.017429344 test cost= 0.018030345 W= [[2.7106097 3.6475966]] b= 0.50249916\n",
      "Epoch: 6500 train cost= 0.013313138 test cost= 0.013785674 W= [[2.7438202 3.6946216]] b= 0.45979413\n",
      "Epoch: 7000 train cost= 0.010173203 test cost= 0.010543796 W= [[2.7734349 3.7352   ]] b= 0.42243433\n",
      "Epoch: 7500 train cost= 0.007776579 test cost= 0.008066571 W= [[2.7997992 3.7702458]] b= 0.38974926\n",
      "Epoch: 8000 train cost= 0.005946350 test cost= 0.006172829 W= [[2.8232331 3.8005395]] b= 0.3611533\n",
      "Epoch: 8500 train cost= 0.004548028 test cost= 0.004724591 W= [[2.8440359 3.8267453]] b= 0.33613357\n",
      "Epoch: 9000 train cost= 0.003479331 test cost= 0.003616764 W= [[2.86248  3.849431]] b= 0.31424296\n",
      "Epoch: 9500 train cost= 0.002662268 test cost= 0.002769094 W= [[2.8788135 3.8690846]] b= 0.29508922\n",
      "Epoch: 10000 train cost= 0.002037439 test cost= 0.002120366 W= [[2.8932652 3.8861206]] b= 0.27833\n",
      "Epoch: 10500 train cost= 0.001559457 test cost= 0.001623762 W= [[2.906041 3.900899]] b= 0.2636654\n",
      "Epoch: 11000 train cost= 0.001193770 test cost= 0.001243580 W= [[2.917324  3.9137242]] b= 0.2508335\n",
      "Epoch: 11500 train cost= 0.000913932 test cost= 0.000952481 W= [[2.9272835 3.9248621]] b= 0.23960517\n",
      "Epoch: 12000 train cost= 0.000699762 test cost= 0.000729570 W= [[2.936066 3.93454 ]] b= 0.22977988\n",
      "Epoch: 12500 train cost= 0.000535822 test cost= 0.000558853 W= [[2.9438078 3.942952 ]] b= 0.22118187\n",
      "Epoch: 13000 train cost= 0.000410313 test cost= 0.000428097 W= [[2.950629 3.950268]] b= 0.21365815\n",
      "Epoch: 13500 train cost= 0.000314232 test cost= 0.000327954 W= [[2.9566336 3.9566336]] b= 0.20707408\n",
      "Epoch: 14000 train cost= 0.000240654 test cost= 0.000251237 W= [[2.9619198 3.9621747]] b= 0.20131244\n",
      "Epoch: 14500 train cost= 0.000184314 test cost= 0.000192472 W= [[2.9665692 3.9669993]] b= 0.19627026\n",
      "Epoch: 15000 train cost= 0.000141188 test cost= 0.000147471 W= [[2.9706542 3.9712005]] b= 0.1918581\n",
      "Epoch: 15500 train cost= 0.000108141 test cost= 0.000112981 W= [[2.9742484 3.974864 ]] b= 0.18799664\n",
      "Epoch: 16000 train cost= 0.000082847 test cost= 0.000086572 W= [[2.9774053 3.978053 ]] b= 0.18461764\n",
      "Epoch: 16500 train cost= 0.000063470 test cost= 0.000066336 W= [[2.9801779 3.9808354]] b= 0.18166138\n",
      "Epoch: 17000 train cost= 0.000048637 test cost= 0.000050841 W= [[2.9826117 3.9832594]] b= 0.17907447\n",
      "Epoch: 17500 train cost= 0.000037259 test cost= 0.000038956 W= [[2.9847505 3.9853802]] b= 0.17681065\n",
      "Epoch: 18000 train cost= 0.000028547 test cost= 0.000029853 W= [[2.9866283 3.9872277]] b= 0.17482874\n",
      "Epoch: 18500 train cost= 0.000021879 test cost= 0.000022882 W= [[2.9882734 3.9888375]] b= 0.17309467\n",
      "Epoch: 19000 train cost= 0.000016768 test cost= 0.000017537 W= [[2.989723  3.9902382]] b= 0.17157601\n",
      "Epoch: 19500 train cost= 0.000012853 test cost= 0.000013445 W= [[2.9909854 3.991472 ]] b= 0.17024912\n",
      "Epoch: 20000 train cost= 0.000009849 test cost= 0.000010304 W= [[2.9921005 3.9925435]] b= 0.16908632\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for step in range(num_steps):\n",
    "    optimizer.apply_gradients(grad(linear_regression, np.float32(X_train), y_train))\n",
    "\n",
    "    if (step + 1) % display_step == 0 or step == 0:\n",
    "        print(\"Epoch:\", '%04d' % (step + 1), \n",
    "              \"train cost=\",\n",
    "              \"{:.9f}\".format(mean_square_fn(linear_regression, np.float32(X_train), y_train)),\n",
    "              \"test cost=\",\n",
    "              \"{:.9f}\".format(mean_square_fn(linear_regression, np.float32(X_test), y_test)),\n",
    "              \"W=\", W.numpy(), \"b=\", b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linear_regression(np.float32(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1262498, shape=(2000, 1), dtype=float32, numpy=\n",
       "array([[0.9013741],\n",
       "       [4.9975348],\n",
       "       [4.6948195],\n",
       "       ...,\n",
       "       [3.2196229],\n",
       "       [3.08029  ],\n",
       "       [2.422932 ]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8946791 ],\n",
       "       [5.00038971],\n",
       "       [4.69610016],\n",
       "       ...,\n",
       "       [3.21725159],\n",
       "       [3.07970747],\n",
       "       [2.42054664]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(y_pred)), y_pred)\n",
    "plt.axis([0, epochs, 0, np.max(loss_history)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow Tutorial",
   "language": "python",
   "name": "tensorflow_tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
